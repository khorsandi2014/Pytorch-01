{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo_PyTorch_Lightning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l1kD7omZW0p"
      },
      "source": [
        "## **TODO:** Set the value of `URL` to the URL from your learning materials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgqnViFfZf0l"
      },
      "source": [
        "URL = None\n",
        "import os\n",
        "assert URL and (type(URL) is str), \"Be sure to initialize URL using the value from your learning materials\"\n",
        "os.environ['URL'] = URL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cefrRtm-Zh4L"
      },
      "source": [
        "%%bash\n",
        "pip install pytorch-lightning\n",
        "wget -q $URL -O ./data.zip\n",
        "mkdir -p data checkpoints\n",
        "find *.zip | xargs unzip -o -d data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj8oTL4LZZXa"
      },
      "source": [
        "## Demo: PyTorch Lightining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oKWxWlmun66"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch as pt\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "pt.set_default_dtype(pt.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHnCB1E-GJPC"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "df = pd.concat(\n",
        "    pd.read_csv(file) for file in Path('data/').glob('part-*.csv')\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sASeKKBzeWMJ"
      },
      "source": [
        "working_df = df.drop('origindatetime_tr', axis = 1)\n",
        "working_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMY68kfpeY7p"
      },
      "source": [
        "test_df = working_df.sample(frac = 0.10, random_state = 42)\n",
        "test_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mm10L82eay4"
      },
      "source": [
        "train_df = working_df.drop(index = test_df.index)\n",
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vYGtKDeajQk"
      },
      "source": [
        "FEATURES = ['origin_block_latitude','origin_block_longitude','destination_block_latitude','destination_block_longitude']\n",
        "TARGET = ['fareamount']\n",
        "\n",
        "BATCH_SIZE = 2 ** 18\n",
        "PIN_MEMORY = True\n",
        "\n",
        "X_train = pt.tensor(train_df[FEATURES].values)\n",
        "X_train = X_train.pin_memory() if PIN_MEMORY else X_train\n",
        "\n",
        "y_train = pt.tensor(train_df[TARGET].values)\n",
        "y_train = y_train.pin_memory() if PIN_MEMORY else y_train\n",
        "\n",
        "train_ds = TensorDataset(y_train, X_train)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, pin_memory = PIN_MEMORY, num_workers = os.cpu_count())\n",
        "\n",
        "X_test = pt.tensor(test_df[FEATURES].values)\n",
        "X_test = X_test.pin_memory() if PIN_MEMORY else X_test\n",
        "\n",
        "y_test = pt.tensor(test_df[TARGET].values)\n",
        "y_test = y_test.pin_memory() if PIN_MEMORY else y_test\n",
        "\n",
        "test_ds = TensorDataset(y_test, X_test)\n",
        "test_dl = DataLoader(test_ds, batch_size = BATCH_SIZE, pin_memory = PIN_MEMORY)\n",
        "                    #  , num_workers = os.cpu_count())\n",
        "\n",
        "len(train_ds), len(test_ds), BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCuJbfShus6a"
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "class TaxiFareRegressor(pl.LightningModule):\n",
        "  def __init__(self, **kwargs):    \n",
        "    super(TaxiFareRegressor, self).__init__()\n",
        "    self.save_hyperparameters()\n",
        "\n",
        "    SEED = int(self.hparams.seed)\n",
        "    pt.manual_seed(SEED)\n",
        "\n",
        "    NUM_FEATURES = int(self.hparams.num_features)\n",
        "    self.layers = pt.nn.Sequential(\n",
        "        pt.nn.Linear(NUM_FEATURES, 1, bias = False)\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.layers(X)\n",
        "\n",
        "  def loss(self, y_est, y):\n",
        "    mse = pt.nn.functional.mse_loss(y_est.squeeze_(), y.squeeze_())\n",
        "    rmse = mse.sqrt()\n",
        "    return mse, rmse\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "      y, X = batch\n",
        "\n",
        "      y_est = self.forward(X)\n",
        "      mse, rmse = self.loss(y_est, y)\n",
        "\n",
        "      self.log('train_mse', mse, prog_bar=True, on_step=True, logger=True)\n",
        "      self.log('train_rmse', rmse, prog_bar=True, on_step=True, logger=True)\n",
        "\n",
        "      return mse\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    y, X = batch\n",
        "\n",
        "    with pt.no_grad():\n",
        "      mse, rmse = self.loss(self.forward(X), y)\n",
        "\n",
        "    self.log('test_mse', mse, prog_bar=True, on_step=True, logger=True)\n",
        "    self.log('test_rmse', rmse, prog_bar=True, on_step=True, logger=True)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return pt.optim.AdamW(self.layers.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEhKjtbec8zM"
      },
      "source": [
        "model = TaxiFareRegressor(**{\n",
        "    'seed': '42',\n",
        "    'lr': '0.03',    \n",
        "    'num_features': '4',\n",
        "    'max_epochs': '1'\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcN8iAaXuw3j"
      },
      "source": [
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from pytorch_lightning.profiler import AdvancedProfiler\n",
        "adv_profiler = AdvancedProfiler()\n",
        "\n",
        "tb_logger = pl_loggers.TensorBoardLogger('lightning_logs/')\n",
        "csv_logger = pl_loggers.CSVLogger(save_dir = \"logs\", \n",
        "                    name = \"taxifare\",\n",
        "                    version = f\"seed_{model.hparams.seed}\")\n",
        "\n",
        "MAX_EPOCHS = int(model.hparams.max_epochs)\n",
        "trainer = pl.Trainer(gpus = 1, \n",
        "                     max_epochs = MAX_EPOCHS, \n",
        "                     default_root_dir='./checkpoints',\n",
        "                     log_every_n_steps=1,\n",
        "                     progress_bar_refresh_rate = 20, \n",
        "                    #  overfit_batches=0.05,\n",
        "                    #  profiler=adv_profiler,\n",
        "                     logger=[tb_logger, csv_logger])\n",
        "\n",
        "trainer.fit(model, train_dataloader=train_dl) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oksDnd_0f__"
      },
      "source": [
        "trainer.callback_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZodkPrFUTDg"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8jYgG2SqgCw"
      },
      "source": [
        "import pandas as pd\n",
        "metrics_df = pd.read_csv(f'logs/taxifare/seed_{model.hparams.seed}/metrics.csv')\n",
        "metrics_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtdZ4o21rVbD"
      },
      "source": [
        "ax = metrics_df[['step', 'train_rmse']].plot('step', 'train_rmse')\n",
        "\n",
        "ax.figure.set_size_inches(12, 6)\n",
        "ax.set_xlabel('step', fontsize = 20)\n",
        "ax.tick_params(axis='x', labelsize=20)\n",
        "ax.tick_params(axis='y', labelsize=20)\n",
        "ax.legend(fontsize = 20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQQu4tip9HFG"
      },
      "source": [
        "trainer.save_checkpoint('checkpoints/model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVZB_5DG8xD-"
      },
      "source": [
        "model = TaxiFareRegressor.load_from_checkpoint('checkpoints/model')\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXNU5sd08jvD"
      },
      "source": [
        "trainer.test(model, test_dl)\n",
        "trainer.callback_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBADfsjEZ7_t"
      },
      "source": [
        "Copyright 2021 CounterFactual.AI LLC. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    }
  ]
}